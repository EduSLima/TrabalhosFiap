---
title: "Análise Qualidade do Vinho"
author: "FIAP-06IA"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    self_contained: true
    thumbnails: false
    lightbox: false
---


```{r knitr_init, echo=FALSE, results="asis", cache=FALSE}
library(rmarkdown)
library(knitr)
library(rmdformats)
library(DT)

## Global options
options(max.print = "75")
opts_chunk$set(echo = FALSE,
	             cache = FALSE,
               prompt = FALSE,
               tidy = FALSE,
               comment = NA,
               message = FALSE,
               warning = FALSE)
opts_knit$set(width = 75)
```

# Inicio

## Introdução

<img src="Arquivos/vinho.jpg" style="width:25%; border:10px solid; margin-right: 20px" align="left">

>Trabalho de conlusão </br>
>Matéria   : CONCEITOS ESTATÍSTICOS PARA IA </br>
>Professora: ADELAIDE ALVES DE OLIVEIRA </br>

</br>

Integrantes do Grupo E2GR:

* EDUARDO MORAIS           [ 334530 ]
+ EDUARDO SIQUEIRA DE LIMA [ 334304 ]
+ GABRIEL SHIKAMA          [ 334068 ]
+ RICARDO CALIMANIS        [ 334759 ]

Análise realizada no dataset WineQuality onde aplicaremos todas as técnicas aprendidas em sala de aula.


## Preparando o Ambiente

### Instalando os pacotes necessários


Instalando os pacotes necessários para realizar as análises 
```{r chunk="idx_01_01", echo=TRUE, eval=TRUE}

#lista de pacotes que iremos utilizar no projeto
Pacotes_Necessarios <- c("ggplot2","readr","dplyr","corrplot","plotly","skimr","GGally","gmodels","ggpubr","caTools",
                         "caret" ,"rpart.plot","DT","e1071","corrgram")

#com base nos pacotes instalados crio uma variavel somente com os pacotes 
#que não temos ainda para realizar a instalação 
#dos pacotes que de fato não possuimos
PacotesNovos <- Pacotes_Necessarios[!(Pacotes_Necessarios %in% installed.packages()[,"Package"])]
if(length(PacotesNovos)){ install.packages(PacotesNovos)} else {print("Todos os Pacotes Estão Instalados")}


```

### Carregando os Pacotes

```{r chunk="idx_01_02", echo=TRUE, eval=TRUE}
lapply(Pacotes_Necessarios, require, character.only = TRUE)
```

## Dataset

### Carregando o DataSet

A fim de facilitar a compreensão e desenvolvimento de nosso codigo decidimos mudar os nomes das colunas do data set, a tabela a baixo indica o nome original do arquivo e o nome que propuzemos

### Lista DE - PARA das colunas

Nome no Arquivo     |  Nome Traduzido
----------------    |-----------------
ID                  |ID (que não sera utilizado)
fixed acidity       |acidez_fixa
volatile acidity    |acidez_volatil
citric acid         |acido_citrico	
residual sugar      |acucar_residual
chlorides           |cloretos
free sulfur dioxide |fsd
total sulfur dioxide|tsd
density             |densidade
pH                  |PH
sulphates           |sulfatos
alcohol             |grau_alcolico
quality             |qualidade
Vinho               |Tipo

```{r chunk="idx_01_03" , echo=TRUE, eval=TRUE}
#Criando uma variável nome_colunas que receberá os nomes das colunas que normalizaremos a fim de facilitar o resto da análise
nome_colunas <- c("id","acidez_fixa","acidez_volatil","acido_citrico","acucar_residual","cloretos", "fsd", "tsd","densidade","PH", 
                  "sulfatos","grau_alcolico","qualidade","tipo")

#uso da biblioteca readr é para obter uma performance de carga melhor que a lib padrão do R
#e escolhemos o read_csv2 justamente pelo fato do arquivo estar separado por ; ao invés de ,
#o separador decimal também não é o . que é convencional e este comando ja os converte facilmente
#skip = 1 para ignorar o cabecalho que mudamos para melhor entendimento

setwd("/mnt/hgfs/kal1s/files/cyberAI/Training/Fiap/MBA/Disciplinas/TrabalhosFiap/EstatisticaIA/Final")
vinhos <- read_csv2("Arquivos/BaseWine_Red_e_White.csv" ,col_names = nome_colunas, skip = 1)

```

# Análise Exploratória

## Observando o DataFrame

Exibindo as Dimensões do dataframe vinhos
```{r chunk="idx_02_01" , echo=TRUE, eval=TRUE}

dim(vinhos)

```


Exibindo a Estrutura do dataframe vinhos
```{r chunk="idx_02_02" , echo=TRUE, eval=TRUE}

str(vinhos)

```

## Validações Iniciais

Exibindo a Sumario e um histograma inicial  do dataframe vinhos

```{r chunk="idx_02_03" , echo=TRUE, eval=TRUE}
options(width = 900)   #definindo o tamanho da area de impressão de saida do markdown
options(max.print=500) # aumentando a saida da lista, sem esta opção alguns resultados tendem a ser cortados
skim(vinhos[, names(vinhos) != "id"] ) #retirando a coluna ID da análise

```

Observa-se que:

* O campo `acucar_residual`,`fsd`, `tsd` possuem um desvio padrão acima das demais variaveis
* A maioria dos histogramas apresenta uma distribuição normal entretanto não centralizado o que pode indicar a presença de outliers


### Checar presença de `nulos`
```{r chunk="idx_02_04" , echo=TRUE, eval=TRUE}
sapply(vinhos, function(x)all(is.na(x)))
```

O resultado acima nos descreve que não há presença de nulos na base, isto é indicado pelo retorno `FALSE` em cada variável

### Checar presença de Registros Duplicados
 
  Para prover melhor performance e acurácia de nossos modelos iremos verificar a existência de registros duplicados e removê-los se existir, mais antes é necessário remover uma coluna, ou simplesmente ignorar, que é a coluna ID que contem algum tipo de código incremental.

```{r chunk="idx_02_05" , echo=TRUE, eval=TRUE}

#removendo a coluna Id que não é necessária para nossa analise
vinhos<- vinhos[-1]


vinhos[duplicated(vinhos, fromLast = TRUE), ]

```

De fato existem 1176 registros duplicados onde:
```{r chunk="idx_02_06" , echo=TRUE, eval=TRUE}
count(vinhos[duplicated(vinhos, fromLast = TRUE), ], tipo)
```

Removendo as linhas duplicadas
```{r chunk="idx_02_07" , echo=TRUE, eval=TRUE}

vinhos<-vinhos[!duplicated(vinhos[-1], fromLast = TRUE), ]

```

### Histograma

Imprimindo Histogramas das variaveis
```{r chunk="idx_02_08" , echo=TRUE, eval=TRUE}
attach(vinhos)

Rotulos_Colunas <-c("id", "acidez_fixa","acidez volatil"	,"acido citrico","acucar residual","cloretos","fsd","tsd","densidade",			
                    "PH","sulfatos","grau alcolico","qualidade","tipo")

grafico_lista <- vector("list", length = length(Rotulos_Colunas)-2)

for(i in 2:13){
  grafico_lista[[i-1]] <- plot_ly(x = as.formula(vinhos[i]),   type = 'histogram', name = Rotulos_Colunas[i])
}  
subplot(grafico_lista,  nrows = 4)


```


Podemos observar que quase em todas variáveis possuem um desenho ser similar à uma distribuição normal no entanto isso se deu pois mais à esquerda exceto grau alcoolico. Isso pode indicar presença de Outliers. A Conslusão que já se pode tirar é que há erros no Teor alcoolico, haja visto que é sabido que não existe vinhos com teor alcoolico a baixo de 8. 


## Explorando o DataSet

  Nosso intuito nesta parte é entender se podemos considerar o dataset como um todo ou se devemos observá-los por tipo de vinho para isso iremos agregar os dados por tipo de vinho 
  e ver como as variáveis se comportam

```{r chunk="idx_02_12" , echo=TRUE, eval=TRUE}
  
aggregate(vinhos[,-12],  by = list(vinhos$tipo),  FUN = sd)

```

Nos parece que há algumas diferenças significativas levando em consideração, os desvios padrão agregado por tipo de vinho onde:

  | Observações
--|-------------------------------------
1 | Acidez fixa é quase o dobro em vinhos `Tintos`
2 | Acidez Volatil é maior 0.7 desvios em `Tintos`
3 | Ácido Cítrico é quase 4 desvios maior em `Brancos`
4 | Cloretos maior que 2 desvios em `Tintos`
5 | Sulfatos (fsd e tsd) é Maior em `Brancos`
6 | Densidade é maior em  `Brancos`

Entretanto a Qualidade não varia, ou seja em nossa perceção as características que determinam qualidade para os vinhos são diferentes e iremos ver a seguir a correlação dessas variáveis.


# Preparação dos Dados

## Inicio

### Transformação de qualidade em variável categórica

Decidimos por classificar a nota da qualidade inicialmente em três grupos:

Grupo   | Notas
--------|----------
Ruim    | 0 ~ 5.99
Regular | 6 ~ 7.99
Bom     | >= 8

Neste caso, poderíamos utilizar algoritmos supervisionados como o K-means pra predizer em qual categoria um vinho se encontra.

Porém, consideramos que isso não faria sentido para rodar os modelos não supervisionados.

Para rodar este modelo, decidimos criar a variável `GrupoQualidade`, sendo qualquer `qualidade` com valor maior ou superior a 6 é classificado como vinho "BOM". A variável `GrupoQualidade` será nossa variável dependente no caso.

```{r chunk="idx_03_01" , echo=TRUE, eval=TRUE}

vinhos$GrupoQualidade  <- as.factor(ifelse(vinhos$qualidade > 6,1,0))
vinhos$GrupoQualidadeF <- as.factor(ifelse(vinhos$qualidade > 'Bom','Regular','Ruim'))

```


  Como Identificamos que pode fazer sentido analisar o vinho de maneira separada por tipo já que muitas variáveis tendem a se comportar de forma diferente vamos iniciar a preparação dos
dados separando o dataset em 2 :
`df_base_tinto` e `df_base_branco`

```{r chunk="idx_03_02" , echo=TRUE, eval=TRUE}
  
  df_base_tinto  <-as.data.frame(subset(vinhos[,1:15], tipo=="RED"))
  df_base_branco <-as.data.frame(subset(vinhos[,1:15], tipo!="RED"))
  
```


## Transformação Box Cox 

  Em estatística, uma transformação de potência é uma família de funções que são aplicadas para criar a transformação monotônica de dados usando funções de potência. Esta é uma técnica de transformação de dados útil usada para estabilizar a variância, tornar os dados mais semelhantes à distribuição normal, melhorar a validade das medidas de associação (como a correlação de Pearson entre as variáveis) e para outros procedimentos de estabilização de dados.

  Tanto a forma linear quanto a logarítmica são dois casos particulares de uma família mais extensa de transformações não-lineares. A transformação de potência é definida como uma função de variação contínua, em relação ao parâmetro de potência ?? (lambda), ou seja, x??. Uma classe geral de transformação que pode ser utilizada é a de Box-Cox, definida por:

para ?? diferente de 0
$$f_\lambda(x) = \frac{(x)^\lambda - 1}{\lambda} $$ 

para ?? = 0
$$f_0 = log(x)$$ 

Se a assimetria for 0, os dados são perfeitamente simétricos.
Como regra geral: Se a assimetria for menor que -1 ou maior que 1, a distribuição é muito distorcida.
Se a assimetria estiver entre -0,5 e 0,5, a distribuição é aproximadamente simétrica.

Usamos a transformação Boxcox e transformamos os dados e depois verificaremos a  assimetria.

### Vinho Tinto

Antes de transformar
```{r chunk="idx_03_01" , echo=TRUE, eval=TRUE}
apply(df_base_tinto[1:12], 2, skewness, na.rm =TRUE)
```

Transformado

```{r chunk="idx_03_02" , echo=TRUE, eval=TRUE}

#preparação para a transformação dos dados
df_prep_tinto <- preProcess(df_base_tinto[,1:12], c("BoxCox", "center", "scale"))
df_tinto <- data.frame(trans = predict(df_prep_tinto, df_base_tinto))

df_tinto

#remove df desnecessario
rm("df_prep_tinto")

#atribui os nomes originais 
colnames(df_tinto) <- colnames(df_base_tinto)

apply(df_tinto[1:12], 2, skewness, na.rm =TRUE)
```

### Vinho Branco

Antes de transformar
```{r chunk="idx_03_02" , echo=TRUE, eval=TRUE}
apply(df_base_branco[1:12], 2, skewness, na.rm =TRUE)
```

Transformado

```{r chunk="idx_03_03" , echo=TRUE, eval=TRUE}

#preparação para a transformação dos dados
df_prep_branco <- preProcess(df_base_branco[,1:12], c("BoxCox", "center", "scale"))
df_branco <- data.frame(trans = predict(df_prep_branco, df_base_branco))

#atribui os nomes originais 
colnames(df_branco) <- colnames(df_base_branco)

#remove df desnecessario
rm("df_prep_branco")


apply(df_branco[1:12], 2, skewness, na.rm =TRUE)
```


## Outliers

A maioria das estatísticas paramétricas, como médias, desvios-padrão e correlações, e todas as estatísticas com base nelas, são altamente sensíveis a outliers. As premissas dos procedimentos estatísticos comuns, como regressão linear e ANOVA, também são baseadas nessas estatísticas, quando outliers podem perturbar a estatística. análise. Assim, nós removemos os outliers.

Possivelmente, o passo mais importante na preparação de dados é identificar outliers. Como se trata de dados multivariados, consideramos apenas aqueles pontos que não possuem nenhum valor de variável de previsão para estar fora dos limites construídos pelos boxplots. A seguinte regra é aplicada:

Um valor preditivo é considerado um valor discrepante somente se for maior que 3 Desvios Padrão. A lógica por trás dessa regra é que os valores extremos extremos estão todos na extremidade superior dos valores e as distribuições são todas positivamente distorcidas.

### Vinho Tinto

#### Identificando os Outliers

Iremos a seguir criar um dataframe somente para ter a quantidade de outliers identificados para cada variável, usaremos o comando abs para obter a posicão absoluta
onde o desvio padrão é > 3 como ja fora transformado no passo anterior

```{r chunk="idx_03_04" , echo=TRUE, eval=TRUE}

outlier <- data.frame(matrix(ncol = 1, nrow = 1))
colnames(outlier)<-"tipo"

outlier$tipo = "Tinto"

outlier$acidez_fixa <- count(df_tinto[abs(df_tinto$acidez_fixa)>3,])
outlier$acidez_volatil <-count(df_tinto[abs(df_tinto$acidez_volatil)>3,])
outlier$acido_citrico <-count(df_tinto[abs(df_tinto$acido_citrico)>3,])
outlier$acucar_residual <-count(df_tinto[abs(df_tinto$acucar_residual)>3,])
outlier$cloretos <-count(df_tinto[abs(df_tinto$cloretos)>3,])
outlier$fsd <-count(df_tinto[abs(df_tinto$fsd)>3,])
outlier$tsd <-count(df_tinto[abs(df_tinto$tsd)>3,])
outlier$densidade <-count(df_tinto[abs(df_tinto$densidade)>3,])
outlier$PH <-count(df_tinto[abs(df_tinto$PH)>3,])
outlier$sulfatos <-count(df_tinto[abs(df_tinto$sulfatos)>3,])
outlier$grau_alcolico <-count(df_tinto[abs(df_tinto$grau_alcolico)>3,])

summary(outlier)

```

Encontramos 67 observações e iremos remover de nossa análise

#### Removendo os outliers


```{r chunk="idx_03_04" , echo=TRUE, eval=TRUE}

df_tinto <- df_tinto[!abs(df_tinto$acidez_fixa)>3,]
df_tinto <- df_tinto[!abs(df_tinto$acidez_volatil)>3,]
df_tinto <- df_tinto[!abs(df_tinto$acido_citrico)>3,]
df_tinto <- df_tinto[!abs(df_tinto$acucar_residual)>3,]
df_tinto <- df_tinto[!abs(df_tinto$cloretos)>3,]
df_tinto <- df_tinto[!abs(df_tinto$fsd)>3,]
df_tinto <- df_tinto[!abs(df_tinto$densidade)>3,]
df_tinto <- df_tinto[!abs(df_tinto$PH)>3,]
df_tinto <- df_tinto[!abs(df_tinto$sulfatos)>3,]
df_tinto <- df_tinto[!abs(df_tinto$grau_alcolico)>3,]

```




#### Validando o Dado {.tabset .tabset-fade}

É possivel notar que após a remoção dos outliers os dados se encontram mais normalizados

##### Antes  

```{r chunk="idx_03_05" , echo=TRUE, eval=TRUE}
attach(df_base_tinto)

Rotulos_Colunas <-c( "acidez_fixa","acidez volatil"	,"acido citrico","acucar residual","cloretos","fsd","tsd","densidade",			
                    "PH","sulfatos","grau alcolico","qualidade")

p_1 <- vector("list", length = length(Rotulos_Colunas)-2)

for(i in 2:12){
  p_1[[i-1]] <- plot_ly(x = as.formula(df_base_tinto[i]),   type = 'histogram', name = Rotulos_Colunas[i])
}  

subplot(p_1,  nrows = 4)
```

##### Depois

```{r chunk="idx_03_06" , echo=TRUE, eval=TRUE}
attach(df_tinto)

p_2 <- vector("list", length = length(Rotulos_Colunas)-2)

for(i in 2:11){
  p_2[[i-1]] <- plot_ly(x = as.formula(df_tinto[i]),   type = 'histogram', name = Rotulos_Colunas[i])
}  

subplot(p_2,  nrows = 4)

```



### Vinho Branco


```{r chunk="idx_03_07" , echo=TRUE, eval=TRUE}

outlier <- data.frame(matrix(ncol = 1, nrow = 1))
colnames(outlier)<-"tipo"

outlier$tipo = "Branco"

outlier$acidez_fixa <- count(df_branco[abs(df_branco$acidez_fixa)>3,])
outlier$acidez_volatil <-count(df_branco[abs(df_branco$acidez_volatil)>3,])
outlier$acido_citrico <-count(df_branco[abs(df_branco$acido_citrico)>3,])
outlier$acucar_residual <-count(df_branco[abs(df_branco$acucar_residual)>3,])
outlier$cloretos <-count(df_branco[abs(df_branco$cloretos)>3,])
outlier$fsd <-count(df_branco[abs(df_branco$fsd)>3,])
outlier$tsd <-count(df_branco[abs(df_branco$tsd)>3,])
outlier$densidade <-count(df_branco[abs(df_branco$densidade)>3,])
outlier$PH <-count(df_branco[abs(df_branco$PH)>3,])
outlier$sulfatos <-count(df_branco[abs(df_branco$sulfatos)>3,])
outlier$grau_alcolico <-count(df_branco[abs(df_branco$grau_alcolico)>3,])

summary(outlier)

```

Encontramos 153 observações fora do padrão e iremos remover de nossa análise

#### Removendo os outliers


```{r chunk="idx_03_08" , echo=TRUE, eval=TRUE}

df_branco <- df_branco[!abs(df_branco$acidez_fixa)>3,]
df_branco <- df_branco[!abs(df_branco$acidez_volatil)>3,]
df_branco <- df_branco[!abs(df_branco$acido_citrico)>3,]
df_branco <- df_branco[!abs(df_branco$cloretos)>3,]
df_branco <- df_branco[!abs(df_branco$fsd)>3,]
df_branco <- df_branco[!abs(df_branco$tsd)>3,]
df_branco <- df_branco[!abs(df_branco$densidade)>3,]
df_branco <- df_branco[!abs(df_branco$PH)>3,]
df_branco <- df_branco[!abs(df_branco$sulfatos)>3,]

```




#### Validando o Dado {.tabset .tabset-fade}

Assim como no vinho tinto, temos a mesma percepção de com poucas extrações o dado ficou também mais proximo do normal 

##### Antes  

```{r chunk="idx_03_05" , echo=TRUE, eval=TRUE}
attach(df_base_branco)

Rotulos_Colunas <-c("id", "acidez_fixa","acidez volatil"	,"acido citrico","acucar residual","cloretos","fsd","tsd","densidade",			
                    "PH","sulfatos","grau alcolico","qualidade","tipo")

p_1 <- vector("list", length = length(Rotulos_Colunas)-2)

for(i in 2:11){
  p_1[[i-1]] <- plot_ly(x = as.formula(df_base_branco[i]),   type = 'histogram', name = Rotulos_Colunas[i])
}  

subplot(p_1,  nrows = 4)
```

##### Depois

```{r chunk="idx_03_06" , echo=TRUE, eval=TRUE}
attach(df_branco)

p_2 <- vector("list", length = length(Rotulos_Colunas)-2)

for(i in 2:11){
  p_2[[i-1]] <- plot_ly(x = as.formula(df_branco[i]),   type = 'histogram', name = Rotulos_Colunas[i])
}  

subplot(p_2,  nrows = 4)

```


# Matriz de Correlação 

  O primeiro passo para iniciar o processo de aplicação de modelos estatísticos é validar as correlações que possam indicar caracteristicas que determinam o fato.E neste caso precisamos saber quais das variáveis podem agregar qualidade ao vinho.
  

## Vinho Tinto 

```{r chunk="idx_03_07" , echo=TRUE, eval=TRUE}

corrplot(cor(df_tinto[1:12]), type = "lower")
```  
 
```{r chunk="idx_03_08" , echo=TRUE, eval=TRUE}

corrgram(df_tinto[1:12], type="data", lower.panel=panel.conf, 
         upper.panel=panel.shade, main= "Correlações para Vinho Tinto", order=T, cex.labels=1.1)
```   


## Vinho Branco  

```{r chunk="idx_03_07" , echo=TRUE, eval=TRUE}

corrplot(cor(df_branco[1:12]), type = "lower")
```  
 
```{r chunk="idx_03_08" , echo=TRUE, eval=TRUE}

corrgram(df_branco, type="data", lower.panel=panel.conf, 
         upper.panel=panel.shade, main= "Correlações para Vinho Branco", order=T, cex.labels=1.1)
```   

# Regressão Linear

### Teoria
  Regressão linear é uma equação para se estimar a condicional (valor esperado) de uma variável y, dados os valores de algumas outras variáveis x.

  Exemplo de regressão linear.
    A regressão, em geral, tem como objectivo tratar de um valor que não se consegue estimar inicialmente.

  A regressão linear é chamada "linear" porque se considera que a relação da resposta às variáveis é uma função linear de alguns parâmetros. Os modelos de regressão que não são uma função linear dos parâmetros se chamam modelos de regressão não-linear. Sendo uma das primeiras formas de análise regressiva a ser estudada rigorosamente, e usada extensamente em aplicações práticas. Isso acontece porque modelos que dependem de forma linear dos seus parâmetros desconhecidos, são mais fáceis de ajustar que os modelos não-lineares aos seus parâmetros, e porque as propriedades estatísticas dos estimadores resultantes são fáceis de determinar.[1]

### Formula 

  $$y_{i} = \alpha + \beta X_{i} + \varepsilon_{i}$$

onde:
  
$$y_{i}$$: Variável explicada (dependente); representa o que o modelo tentará prever
$$\alpha$$: É uma constante, que representa a interceptação da reta com o eixo vertical;
$$\beta$$: Representa a inclinação (coeficiente angular) em relação à variável explicativa;
$$X_{i}$$: Variável explicativa (independente);
$$\varepsilon _{i}}$$: Representa todos os factores residuais mais os possíveis erros de medição. O seu comportamento é aleatório, devido à natureza dos factores que encerra. Para que essa fórmula possa ser aplicada, os erros devem satisfazer determinadas hipóteses, que são: terem distribuição normal, com a mesma variância independentes e independentes da variável explicativa X, ou seja, i.i.d. (independentes e identicamente distribuídas).

fonte: https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear


## Vinho Tinto

### Separação dos Dados Treino e Teste

```{r chunk="idx_04_01" , echo=TRUE, eval=TRUE}
set.seed(1914) #seed relacionado ao ano de fundação do nosso amado e glorioso Palestra Itália

split <- sample.split(df_tinto$qualidade, SplitRatio = 0.8)

#dividindo o dataset para treino e teste
df_vinho_tinto_treino <- subset(df_tinto, split == TRUE)
df_vinho_tinto_teste  <- subset(df_tinto, split == FALSE)

```


### Primeiro Modelo

```{r chunk="idx_04_02" , echo=TRUE, eval=TRUE}

Modelo_01 <- lm(qualidade~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, 
                data = df_vinho_tinto_treino)

summary(Modelo_01)
```

## Vinho Branco

### Separação dos Dados Treino e Teste

```{r chunk="idx_04_01" , echo=TRUE, eval=TRUE}
set.seed(1914) #seed relacionado ao ano de fundação do nosso amado e glorioso Palestra Itália

split <- sample.split(df_branco$qualidade, SplitRatio = 0.8)

#dividindo o dataset para treino e teste
df_vinho_branco_treino <- subset(df_branco, split == TRUE)
df_vinho_branco_teste  <- subset(df_branco, split == FALSE)

```

### Primeiro Modelo

```{r chunk="idx_04_05" , echo=TRUE, eval=TRUE}

Modelo_01 <- lm(qualidade~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, 
                data = df_vinho_branco_treino)

summary(Modelo_01)
```



# Árvore de Regressão

## Técnica

É muito similar a árvore de decisão, pois segue a mesma ideia: um conjunto de nós de DECISÃO/PERGUNTAS partindo de exemplos.

A única diferença é que a resposta é um número ao invés de uma categoria.

A obtenção de árvores de regressão usando o R é feita por meio da função
rpart, tal como nas árvores de decisão. 

## Vinho Tinto
```{r chunk="idx_05_01" , echo=TRUE, eval=TRUE}
RT_Modelo_01 <- rpart(qualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_vinho_tinto_treino)
summary(RT_Modelo_01)
rpart.plot(RT_Modelo_01, digits = 9, fallen.leaves = TRUE, box.palette="RdBu", shadow.col="gray", nn=TRUE)

```



O Modelo apresentado acima teve um desepenho melhor que Regressão Linear Observamos que a variavel Grau Alcoolico é a variavel que possui o maior peso pois ela está no node mais alto da arvore.


### Análise da Qualidade do Modelo (Matriz de Confusão)

```{r chunk="idx_05_02" , echo=TRUE, eval=TRUE}

RT_preditor <- predict(RT_Modelo_01, newdata = df_vinho_tinto_teste)
RT_Valores_Corte <- as.factor(ifelse(RT_preditor > 6,1,0))
confusionMatrix(RT_Valores_Corte, df_vinho_tinto_teste$GrupoQualidade)

```

86% de acertividade 

## Vinho Branco

```{r chunk="idx_05_03" , echo=TRUE, eval=TRUE}
RT_Modelo_01 <- rpart(qualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_vinho_branco_treino)
summary(RT_Modelo_01)
rpart.plot(RT_Modelo_01, digits = 9, fallen.leaves = TRUE, box.palette="RdBu", shadow.col="gray", nn=TRUE)

```

Nota se que para determinar a qualidade do vinho branco utiliza-se menos variáveis que para vinho tinto


```{r chunk="idx_05_04" , echo=TRUE, eval=TRUE}

RT_preditor <- predict(RT_Modelo_01, newdata = df_vinho_branco_teste)
RT_Valores_Corte <- as.factor(ifelse(RT_preditor > 6,1,0))
confusionMatrix(RT_Valores_Corte, df_vinho_branco_teste$GrupoQualidade)

```

Para vinho branco temos uma acurácia de 78%

# Árvore de Decisão

### Técnica

É muito utilizada para aprendizagem indutiva e é extremamente prática.

O conhecimento da Árvore de Decisão será baseado em uma estrutura de árvore para assim podermos realizar decisão. Porém, caso não queira representar em estruturá de árvores, pode ser facilmente representada por regras "se/então". Pode-se utilizar tanto em problemas supervisionados quanto não supervisionados.

A árvore decisão também consegue descobrir quais são os atributos de maior importância para predição formando uma estrutura de nós. 

A base é a mesma da árvore de regressão.

Classe de algoritmos de aprendizado baseado na árvore de decisão: ID3("top-down"), C4.5 etc.

É importante ressaltar que uanto menor a árvore, melhor será a indução. Isso basicamente quer dizer que: caso fique grande, pode cair num problema de overfitting ("100% de acerto").

Outra coisa que precisa-se lembrar em uma Árvore de Decisão é a entropia, a qual diz o quanto um conjunto de dados aleatório está "impuro".
E sempre varia entre 0 e 1, de acordo com a proporção de +/- no conjunto. Vale lembrar que a entropia é importante para o cálculo de ganho de informação para a árvore.

A entropia (binária) é dada pela seguinte fórmula:

$$Entropia(S) = -\sum p_{+} log_{2}  p_{+} - p_{-} log_{2} p_{-}$$

onde:

S: coleção S contendo exemplos
p(+): proporção de exemplos positivos em S;
p(-): proporção de exemplos negativos em S

Referencia:
http://web.tecnico.ulisboa.pt/ana.freitas/bioinformatics.ath.cx/bioinformatics.ath.cx/indexf23d.html?id=199

## Vinho Tinto

```{r chunk="idx_06_01" , echo=TRUE, eval=TRUE}

DT_Modelo01 <-rpart(GrupoQualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_vinho_tinto_treino)

summary(DT_Modelo01)
rpart.plot(DT_Modelo01, digits = 19, fallen.leaves = TRUE)

```

### Análise da Qualidade do Modelo

```{r chunk="idx_06_02" , echo=TRUE, eval=TRUE}
DT_Preditor <- as.data.frame(predict(DT_Modelo01, newdata = df_vinho_tinto_teste))
DT_Preditor$factor <- as.factor(ifelse(DT_Preditor[["1"]] > DT_Preditor[["0"]],1,0))
confusionMatrix(DT_Preditor$factor, df_vinho_tinto_teste$GrupoQualidade)
```

Até agora notamos que este foi o modelo que mais acertou com `86%` de acurácia, justamente por que a técnica é capaz de prever com maior exatidao quais as variaveis mais importantes para determinar a qualidade.


## Vinho Branco

```{r chunk="idx_06_03" , echo=TRUE, eval=TRUE}

DT_Modelo01 <-rpart(GrupoQualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_base_branco)

summary(DT_Modelo01)
rpart.plot(DT_Modelo01, digits = 19, fallen.leaves = TRUE)

```

```{r chunk="idx_06_04" , echo=TRUE, eval=TRUE}
DT_Preditor <- as.data.frame(predict(DT_Modelo01, newdata = df_vinho_branco_teste))
DT_Preditor$factor <- as.factor(ifelse(DT_Preditor[["1"]] > DT_Preditor[["0"]],1,0))
confusionMatrix(DT_Preditor$factor, df_vinho_branco_teste$GrupoQualidade)
```

notamos que acertamos em 77% dos casos

# Modelo 4:  Regressão Logística

## Técnica

A regressão logística é um modelo no qual classificamos na qual a variável dependente possuem valores binários (intervalos entre 0 e 1), ou seja, um ou o outro e as independentes podem ser categóricas ou não.

Este tipo de modelo lida muito bem com variáveis de entrada (independentes) de tipo categórica e possui um grau relativamente alto de confiabilidade.

Podemos dizer de modo geral que funciona como uma regressão linear, com exceção de que as variáveis dependentes devem ser categóricas e utiliza o método de máxima verossimilhança, ao invés dos mínimos quadrados como na regressão linear.

Como vimos, nosso dataset possui apenas dados numéricos, com exceção do tipo de vinho.

### Criando modelo Árvore de Regressão Logística com todas as variáveis (quality: variável principal)


## Vinho Tinto

```{r chunk="idx_07_01" , echo=TRUE, eval=TRUE}

RL_Modelo01 <- glm(qualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_vinho_tinto_treino)
summary(RL_Modelo01)
```

```{r chunk="idx_07_02" , echo=TRUE, eval=TRUE}

RL_Preditor <- predict.glm(RL_Modelo01, newdata = df_vinho_tinto_teste, type = 'response')
RL_Preditor_Corte <- as.factor(ifelse(RL_Preditor > 6,1,0))
confusionMatrix(RL_Preditor_Corte, df_vinho_tinto_teste$GrupoQualidade)

```

86% adicionar texto explicativo

## Vinho Branco

```{r chunk="idx_07_03" , echo=TRUE, eval=TRUE}

RL_Modelo01 <- glm(qualidade ~ acidez_fixa+acidez_volatil+acido_citrico+acucar_residual+cloretos+densidade+fsd+grau_alcolico+PH+sulfatos+tsd, data = df_vinho_branco_treino)
summary(RL_Modelo01)
```

```{r chunk="idx_07_04" , echo=TRUE, eval=TRUE}

RL_Preditor <- predict.glm(RL_Modelo01, newdata = df_vinho_branco_teste, type = 'response')
RL_Preditor_Corte <- as.factor(ifelse(RL_Preditor > 6,1,0))
confusionMatrix(RL_Preditor_Corte, df_vinho_branco_teste$GrupoQualidade)

```
78%


# PCA

adicionar algo sobre o pca

## Vinho Tinto

```{r chunk="idx_08_01" , echo=TRUE, eval=TRUE}

TintoPCA = prcomp(df_base_tinto[1:12] , scale. = TRUE)

summary(TintoPCA)

plot(1:12, TintoPCA$sdev^2, type = "b", xlab = "Componente",
     ylab = "Variância", pch = 20, cex.axis = 0.8, cex.lab = 0.8)

```

## Vinho Branco

```{r chunk="idx_08_02" , echo=TRUE, eval=TRUE}

BrancoPCA = prcomp(df_base_branco[1:12], scale. = TRUE)

summary(BrancoPCA)

plot(1:12, BrancoPCA$sdev^2, type = "b", xlab = "Componente",
     ylab = "Variância", pch = 20, cex.axis = 0.8, cex.lab = 0.8)

```

# K-Means

## Vinho Tinto

## Vinho Branco

# Conclusões
